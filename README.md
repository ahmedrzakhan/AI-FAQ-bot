# ğŸ¤– AI FAQ Bot - Intelligent Customer Support System

[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

A production-ready AI-powered FAQ bot that combines semantic search with intelligent response generation. Built with modern AI technologies including vector databases, multiple LLM providers, and comprehensive monitoring.

## ğŸŒŸ **Key Features**

### ğŸ§  **Advanced AI Capabilities**

- **Semantic Search**: Understanding meaning, not just keywords using ChromaDB vector database
- **Multi-AI Support**: OpenAI GPT-3.5 + Google Gemini with intelligent fallback
- **Context-Aware Responses**: Natural, conversational answers powered by RAG architecture
- **Smart Fallback System**: Ensures users always get helpful responses

### ğŸ—ï¸ **Production Architecture**

- **RESTful API**: FastAPI backend with automatic documentation
- **Modern Frontend**: Beautiful Streamlit interface with dark theme
- **Vector Database**: ChromaDB for lightning-fast semantic similarity search
- **Containerized**: Docker deployment for consistent environments
- **Monitoring**: LangSmith integration for AI observability and analytics

### ğŸš€ **Enterprise Features**

- **Rate Limiting**: Prevents abuse and controls costs
- **Error Handling**: Graceful degradation and comprehensive logging
- **Health Checks**: API monitoring and status endpoints
- **Scalable Design**: Ready for production deployment
- **Cost Optimization**: Free-tier friendly with usage controls

## ğŸ¯ **Demo**

![FAQ Bot Interface](images/ss1.png)

**Sample Questions to Try**:

- "What is your return policy?"
- "How long does shipping take?"
- "What payment methods do you accept?"
- "Help me track my order"

## ğŸ› ï¸ **Technology Stack**

### **Backend Technologies**

| Component           | Technology                    | Purpose                        |
| ------------------- | ----------------------------- | ------------------------------ |
| **API Framework**   | FastAPI                       | High-performance REST API      |
| **Vector Database** | ChromaDB                      | Semantic search and embeddings |
| **AI Models**       | OpenAI GPT-3.5, Google Gemini | Natural language generation    |
| **Monitoring**      | LangSmith                     | AI observability and analytics |
| **Embedding Model** | all-MiniLM-L6-v2              | Text-to-vector conversion      |

### **Frontend & DevOps**

| Component                  | Technology            | Purpose                   |
| -------------------------- | --------------------- | ------------------------- |
| **UI Framework**           | Streamlit             | Interactive web interface |
| **Containerization**       | Docker                | Consistent deployment     |
| **Cloud Platform**         | Google Cloud Platform | Scalable hosting          |
| **Environment Management** | Docker Compose        | Local development         |

## ğŸš€ **Quick Start**

### **Option 1: Docker (Recommended)**

```bash
# Clone the repository
git clone https://github.com/yourusername/ai-faq-bot.git
cd ai-faq-bot

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Build and run with Docker
docker build -t faq-bot .
docker run -p 8000:8000 --env-file .env faq-bot

# Access the API
open http://localhost:8000

# Run Streamlit frontend (in another terminal)
cd frontend
pip install -r requirements.txt
streamlit run app.py
```

### **Option 2: Local Development**

```bash
# Backend setup
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py

# Frontend setup (in another terminal)
cd frontend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
streamlit run app.py
```

## âš™ï¸ **Configuration**

### **Environment Variables**

Create a `.env` file in the project root:

```env
# AI Model API Keys
GOOGLE_API_KEY=your_google_gemini_api_key
OPENAI_API_KEY=your_openai_api_key_optional

# LangSmith Monitoring (Optional)
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_PROJECT=faq-bot
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Application Settings
ENVIRONMENT=development
DEBUG=true
```

### **Getting API Keys**

1. **Google Gemini API**:

   - Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Free tier: 60 requests/minute

2. **OpenAI API** (Optional):

   - Visit [OpenAI Platform](https://platform.openai.com/api-keys)
   - Pay-per-use pricing

3. **LangSmith** (Optional):
   - Visit [LangSmith](https://smith.langchain.com/)
   - Free tier: 5,000 traces/month

## ğŸ—ï¸ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚    â”‚    FastAPI      â”‚    â”‚   ChromaDB      â”‚
â”‚   Frontend      â”‚â”€â”€â”€â–¶â”‚    Backend      â”‚â”€â”€â”€â–¶â”‚ Vector Database â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LangSmith     â”‚    â”‚  AI Models      â”‚    â”‚   User Query    â”‚
â”‚   Monitoring    â”‚â—€â”€â”€â”€â”‚ OpenAI/Gemini   â”‚â—€â”€â”€â”€â”‚   Processing    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow**

1. **User Input**: Question submitted via Streamlit interface
2. **Vector Search**: ChromaDB finds semantically similar FAQs
3. **Context Creation**: Relevant FAQs assembled as context
4. **AI Generation**: OpenAI/Gemini generates natural response
5. **Response Delivery**: User receives conversational answer
6. **Monitoring**: LangSmith tracks performance and costs

## ğŸ“Š **Project Structure**

```
ai-faq-bot/
â”œâ”€â”€ ğŸ“ backend/
â”‚   â”œâ”€â”€ ğŸ main.py              # FastAPI application
â”‚   â”œâ”€â”€ ğŸ—„ï¸ database.py          # ChromaDB integration
â”‚   â”œâ”€â”€ ğŸ“Š langsmith_config.py  # AI monitoring setup
â”‚   â””â”€â”€ ğŸ“‹ requirements.txt     # Backend dependencies
â”œâ”€â”€ ğŸ“ frontend/
â”‚   â”œâ”€â”€ ğŸ¨ app.py              # Streamlit interface
â”‚   â””â”€â”€ ğŸ“‹ requirements.txt     # Frontend dependencies
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ ğŸ“„ faq_data.json       # FAQ knowledge base
â”œâ”€â”€ ğŸ“ deployment/
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile          # Container configuration
â”‚   â”œâ”€â”€ â˜ï¸ app.yaml            # GCP App Engine config
â”‚   â””â”€â”€ ğŸ”§ docker-compose.yml  # Local development
â”œâ”€â”€ ğŸ“„ README.md               # This file
â”œâ”€â”€ ğŸ”’ .env.example            # Environment template
â””â”€â”€ ğŸ“ requirements.txt        # Root dependencies
```

## ğŸ”§ **API Documentation**

Once running, visit:

- **Interactive API Docs**: http://localhost:8000/docs
- **API Schema**: http://localhost:8000/redoc

### **Key Endpoints**

| Endpoint            | Method | Description                 |
| ------------------- | ------ | --------------------------- |
| `/ask`              | POST   | Main FAQ query endpoint     |
| `/health`           | GET    | System health check         |
| `/faqs`             | GET    | List all available FAQs     |
| `/debug`            | GET    | System debugging info       |
| `/test-gemini`      | POST   | Test Gemini AI specifically |
| `/monitoring/stats` | GET    | AI monitoring statistics    |

### **Example API Usage**

```bash
# Ask a question
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is your return policy?"}'

# Check system health
curl "http://localhost:8000/health"
```

## ğŸŒ©ï¸ **Cloud Deployment**

### **Google Cloud Platform (Free Tier)**

#### **Option 1: App Engine (Recommended)**

```bash
# Setup
gcloud init
gcloud projects create your-faq-bot-project
gcloud config set project your-faq-bot-project
gcloud services enable appengine.googleapis.com

# Deploy
gcloud app deploy deployment/app.yaml

# View
gcloud app browse
```

**Free Tier Benefits**:

- 28 instance hours/day (FREE)
- Automatic scaling to zero
- Built-in load balancing

#### **Option 2: Cloud Run**

```bash
# Deploy container
gcloud run deploy faq-bot \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 512Mi \
  --max-instances 1
```

**Free Tier Benefits**:

- 2M requests/month (FREE)
- Pay-per-request model
- Scales to zero automatically

### **Environment Variables for Production**

```bash
# Set production environment variables
gcloud app deploy --set-env-vars \
  GOOGLE_API_KEY=your_key,\
  LANGCHAIN_API_KEY=your_key,\
  ENVIRONMENT=production
```

## ğŸ“ˆ **Monitoring & Analytics**

### **LangSmith Dashboard Features**

- ğŸ“Š **Performance Metrics**: Response times, success rates
- ğŸ’° **Cost Tracking**: Token usage and API costs per model
- ğŸ” **Conversation Tracing**: Full request/response logs
- ğŸ¯ **A/B Testing**: Compare AI model performance
- ğŸ“ **User Feedback**: Collect and analyze user ratings

### **Key Metrics to Monitor**

- **Response Quality**: User satisfaction scores
- **Performance**: Average response time < 2s
- **Cost Efficiency**: Cost per successful query
- **Error Rates**: Failed requests < 5%
- **Usage Patterns**: Peak usage times and popular queries

## ğŸ§ª **Testing**

### **Manual Testing Checklist**

- [ ] Basic FAQ queries work correctly
- [ ] AI fallback system functions
- [ ] Rate limiting prevents abuse
- [ ] Error handling graceful
- [ ] Monitoring captures data

## ğŸ”’ **Security & Best Practices**

### **API Security**

- Rate limiting on all endpoints
- Input validation and sanitization
- Environment variable protection
- CORS properly configured

### **Data Privacy**

- No user data stored permanently
- API keys secured in environment variables
- Conversation logs can be disabled

### **Production Considerations**

- Health checks for monitoring
- Graceful error handling
- Automatic failover between AI models
- Cost monitoring and alerts

## ğŸ¯ **Use Cases & Applications**

### **Business Applications**

- **Customer Support**: 24/7 automated first-line support
- **Internal Help Desk**: Employee self-service portal
- **Product Documentation**: Interactive user guides
- **Sales Support**: Pre-sales question automation

### **Technical Applications**

- **API Documentation**: Interactive developer support
- **Troubleshooting**: Automated technical support
- **Knowledge Base**: Searchable company information
- **Training**: Employee onboarding assistance

### **Development Setup**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ† **Showcase**

This project demonstrates expertise in:

- **Modern AI Development**: RAG, vector databases, multi-model systems
- **Full-Stack Development**: API design, frontend development, containerization
- **Cloud Engineering**: GCP deployment, monitoring, cost optimization
- **Production Systems**: Error handling, monitoring, scalability
- **Developer Experience**: Documentation, testing, CI/CD

---

**â­ If this project helped you, please give it a star! â­**

_Built with â¤ï¸ using cutting-edge AI technologies_
